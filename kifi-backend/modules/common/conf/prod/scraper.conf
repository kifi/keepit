## Config for the scraper server

application.global="com.keepit.scraper.ScraperGlobal"

include "prod.conf"

application.router=scraper.Routes

application.name="SCRAPER"

statsd {
  stat.prefix = "scraper"
}

airbrake {
  key = "51802b68d8c10ec2e806ed37bce4c429" 
}

cdn {
  bucket = "images-b-prod"
  base = "//djty7jcqog9qu.cloudfront.net"
}

scraper {

  interval {
    min = 24                        # hours
    max = 1024                      # hours
    increment = 6                   # hours
    decrement = 2                   # hours
  }

  queue {
    terminateThreshold = 120000
    sizeThreshold = 100
    terminatorFreq = 5
  }

  http {
    fetcherEnforcerFreq = 5
    fetcherQSizeThreshold = 100
  }

  initialBackoff = 3                 # hours
  maxBackoff = 1024                  # hours
  maxRandomDelay = 600               # seconds
  changeThreshold = 0.5
  pullMultiplier = 8
  pullFrequency = 5                  # seconds
  scrapePendingFrequency = 30        # seconds
  queued = true
  async = false
  actorTimeout = 20000
  syncAwaitTimeout = 20000
  serviceCallTimeout = 20000
  batchSize = 10
  batchMax = 50
  pendingOverdueThreshold = 20       # minutes
  checkOverdueCountFrequency = 20    # minutes
  overdueCountThreshold = 1000
}

# ~~~~~~~~~~~~~~~~~~~~~~
# ForkJoin Pool
# ~~~~~~~~~~~~~~~~~~~~~~
fork-join-pool {
  parallelism = 128
}

# ~~~~~~~~~~~~~~~~~~~~~~
# Embedly
# ~~~~~~~~~~~~~~~~~~~~~~
embedly {
  enabled = true
  key = "e46ecae2611d4cb29342fddb0e666a29"
}
